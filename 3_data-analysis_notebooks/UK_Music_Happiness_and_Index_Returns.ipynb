{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThalyaGIT/UK-Music-Index-Returns/blob/main/3_data-analysis_notebooks/UK_Music_Happiness_and_Index_Returns.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 302,
      "metadata": {
        "id": "K2au3b8sOvGA"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tabulate import tabulate\n",
        "from scipy import stats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 303,
      "metadata": {
        "id": "Xn0nF6QAPn2A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aae7bed8-4263-444b-b7ad-276c87a3f681"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Day:\n",
            "  Lower Bound (5th percentile) of Change in SWAV: -0.017645633864244135\n",
            "  Upper Bound (95th percentile) of Change in SWAV: 0.01428761508293462\n",
            "  Number of rows in the middle 90%: 1550\n",
            "\n",
            "3 Day:\n",
            "  Lower Bound (5th percentile) of Change in SWAV: -0.022834919567331625\n",
            "  Upper Bound (95th percentile) of Change in SWAV: 0.02174560961157004\n",
            "  Number of rows in the middle 90%: 1546\n",
            "\n",
            "5 Day:\n",
            "  Lower Bound (5th percentile) of Change in SWAV: -0.027631647023818887\n",
            "  Upper Bound (95th percentile) of Change in SWAV: 0.024341940135737324\n",
            "  Number of rows in the middle 90%: 1540\n",
            "\n",
            "10 Day:\n",
            "  Lower Bound (5th percentile) of Change in SWAV: -0.03687231865211388\n",
            "  Upper Bound (95th percentile) of Change in SWAV: 0.03412305039189226\n",
            "  Number of rows in the middle 90%: 1527\n",
            "\n",
            "20 Day:\n",
            "  Lower Bound (5th percentile) of Change in SWAV: -0.048911884135500065\n",
            "  Upper Bound (95th percentile) of Change in SWAV: 0.04711551536197874\n",
            "  Number of rows in the middle 90%: 1499\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Open CSV into dataframe\n",
        "url_1_day = 'https://raw.githubusercontent.com/ThalyaGIT/UK-Music-Index-Returns/main/0-data-gold/data_1_days.csv'\n",
        "url_3_day = 'https://raw.githubusercontent.com/ThalyaGIT/UK-Music-Index-Returns/main/0-data-gold/data_3_days.csv'\n",
        "url_5_day = 'https://raw.githubusercontent.com/ThalyaGIT/UK-Music-Index-Returns/main/0-data-gold/data_5_days.csv'\n",
        "url_10_day = 'https://raw.githubusercontent.com/ThalyaGIT/UK-Music-Index-Returns/main/0-data-gold/data_10_days.csv'\n",
        "url_20_day = 'https://raw.githubusercontent.com/ThalyaGIT/UK-Music-Index-Returns/main/0-data-gold/data_20_days.csv'\n",
        "\n",
        "df_1_day = pd.read_csv(url_1_day)\n",
        "df_3_day = pd.read_csv(url_3_day)\n",
        "df_5_day = pd.read_csv(url_5_day)\n",
        "df_10_day = pd.read_csv(url_10_day)\n",
        "df_20_day = pd.read_csv(url_20_day)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming the data has been loaded into the following DataFrames\n",
        "# df_1_day = pd.read_csv(url_1_day)\n",
        "# df_3_day = pd.read_csv(url_3_day)\n",
        "# df_5_day = pd.read_csv(url_5_day)\n",
        "# df_10_day = pd.read_csv(url_10_day)\n",
        "# df_20_day = pd.read_csv(url_20_day)\n",
        "\n",
        "# List of DataFrames\n",
        "dataframes = {\n",
        "    \"1 Day\": df_1_day,\n",
        "    \"3 Day\": df_3_day,\n",
        "    \"5 Day\": df_5_day,\n",
        "    \"10 Day\": df_10_day,\n",
        "    \"20 Day\": df_20_day\n",
        "}\n",
        "\n",
        "# Function to filter and print the middle 90% of \"Change in SWAV\"\n",
        "def filter_middle_90_percent(df, name):\n",
        "    lower_bound = df['Change in SWAV'].quantile(0.05)  # 5th percentile\n",
        "    upper_bound = df['Change in SWAV'].quantile(0.95)  # 95th percentile\n",
        "\n",
        "    # Filter the DataFrame to keep only the middle 90% of data\n",
        "    middle_90_df = df[(df['Change in SWAV'] >= lower_bound) & (df['Change in SWAV'] <= upper_bound)]\n",
        "\n",
        "    print(f\"{name}:\")\n",
        "    print(f\"  Lower Bound (5th percentile) of Change in SWAV: {lower_bound}\")\n",
        "    print(f\"  Upper Bound (95th percentile) of Change in SWAV: {upper_bound}\")\n",
        "    print(f\"  Number of rows in the middle 90%: {len(middle_90_df)}\")\n",
        "    print(\"\")\n",
        "\n",
        "# Loop through each DataFrame and filter the middle 90% of data\n",
        "for name, df in dataframes.items():\n",
        "    filter_middle_90_percent(df, name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D4v2bMvV2Ih"
      },
      "source": [
        "# **Main**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "metadata": {
        "id": "3qHCM4vZWLh5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2a68d111-a740-46a1-c0ea-d321e45d68fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f63b58d0e20>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_1dc74_row1_col1, #T_1dc74_row1_col3, #T_1dc74_row2_col1, #T_1dc74_row2_col3, #T_1dc74_row2_col4, #T_1dc74_row3_col1, #T_1dc74_row3_col3, #T_1dc74_row3_col4, #T_1dc74_row3_col6, #T_1dc74_row4_col1, #T_1dc74_row4_col2, #T_1dc74_row4_col3, #T_1dc74_row4_col4, #T_1dc74_row4_col6 {\n",
              "  background-color: red;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_1dc74\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_1dc74_level0_col0\" class=\"col_heading level0 col0\" >Days</th>\n",
              "      <th id=\"T_1dc74_level0_col1\" class=\"col_heading level0 col1\" >FTSE100 Coef</th>\n",
              "      <th id=\"T_1dc74_level0_col2\" class=\"col_heading level0 col2\" >MSCIUK Coef</th>\n",
              "      <th id=\"T_1dc74_level0_col3\" class=\"col_heading level0 col3\" >FTSEAllShare Coef</th>\n",
              "      <th id=\"T_1dc74_level0_col4\" class=\"col_heading level0 col4\" >FTSE250 Coef</th>\n",
              "      <th id=\"T_1dc74_level0_col5\" class=\"col_heading level0 col5\" >FTSESmallCap Coef</th>\n",
              "      <th id=\"T_1dc74_level0_col6\" class=\"col_heading level0 col6\" >FTSEAIM Coef</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_1dc74_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_1dc74_row0_col0\" class=\"data row0 col0\" >1</td>\n",
              "      <td id=\"T_1dc74_row0_col1\" class=\"data row0 col1\" >-1.000000</td>\n",
              "      <td id=\"T_1dc74_row0_col2\" class=\"data row0 col2\" >0.330000</td>\n",
              "      <td id=\"T_1dc74_row0_col3\" class=\"data row0 col3\" >-0.750000</td>\n",
              "      <td id=\"T_1dc74_row0_col4\" class=\"data row0 col4\" >0.300000</td>\n",
              "      <td id=\"T_1dc74_row0_col5\" class=\"data row0 col5\" >0.910000</td>\n",
              "      <td id=\"T_1dc74_row0_col6\" class=\"data row0 col6\" >1.670000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_1dc74_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_1dc74_row1_col0\" class=\"data row1 col0\" >3</td>\n",
              "      <td id=\"T_1dc74_row1_col1\" class=\"data row1 col1\" >-4.740000</td>\n",
              "      <td id=\"T_1dc74_row1_col2\" class=\"data row1 col2\" >-1.760000</td>\n",
              "      <td id=\"T_1dc74_row1_col3\" class=\"data row1 col3\" >-3.930000</td>\n",
              "      <td id=\"T_1dc74_row1_col4\" class=\"data row1 col4\" >-0.770000</td>\n",
              "      <td id=\"T_1dc74_row1_col5\" class=\"data row1 col5\" >1.090000</td>\n",
              "      <td id=\"T_1dc74_row1_col6\" class=\"data row1 col6\" >-0.170000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_1dc74_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_1dc74_row2_col0\" class=\"data row2 col0\" >5</td>\n",
              "      <td id=\"T_1dc74_row2_col1\" class=\"data row2 col1\" >-7.100000</td>\n",
              "      <td id=\"T_1dc74_row2_col2\" class=\"data row2 col2\" >-2.840000</td>\n",
              "      <td id=\"T_1dc74_row2_col3\" class=\"data row2 col3\" >-6.320000</td>\n",
              "      <td id=\"T_1dc74_row2_col4\" class=\"data row2 col4\" >-3.410000</td>\n",
              "      <td id=\"T_1dc74_row2_col5\" class=\"data row2 col5\" >0.450000</td>\n",
              "      <td id=\"T_1dc74_row2_col6\" class=\"data row2 col6\" >-2.980000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_1dc74_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_1dc74_row3_col0\" class=\"data row3 col0\" >10</td>\n",
              "      <td id=\"T_1dc74_row3_col1\" class=\"data row3 col1\" >-10.150000</td>\n",
              "      <td id=\"T_1dc74_row3_col2\" class=\"data row3 col2\" >-2.920000</td>\n",
              "      <td id=\"T_1dc74_row3_col3\" class=\"data row3 col3\" >-9.630000</td>\n",
              "      <td id=\"T_1dc74_row3_col4\" class=\"data row3 col4\" >-7.870000</td>\n",
              "      <td id=\"T_1dc74_row3_col5\" class=\"data row3 col5\" >-1.950000</td>\n",
              "      <td id=\"T_1dc74_row3_col6\" class=\"data row3 col6\" >-10.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_1dc74_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_1dc74_row4_col0\" class=\"data row4 col0\" >20</td>\n",
              "      <td id=\"T_1dc74_row4_col1\" class=\"data row4 col1\" >-4.480000</td>\n",
              "      <td id=\"T_1dc74_row4_col2\" class=\"data row4 col2\" >-6.580000</td>\n",
              "      <td id=\"T_1dc74_row4_col3\" class=\"data row4 col3\" >-4.990000</td>\n",
              "      <td id=\"T_1dc74_row4_col4\" class=\"data row4 col4\" >-7.680000</td>\n",
              "      <td id=\"T_1dc74_row4_col5\" class=\"data row4 col5\" >1.360000</td>\n",
              "      <td id=\"T_1dc74_row4_col6\" class=\"data row4 col6\" >-11.400000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 304
        }
      ],
      "source": [
        "# @title\n",
        "## Main Script\n",
        "\n",
        "# Initialize an empty list to store results\n",
        "results = []\n",
        "\n",
        "indices = ['FTSE100', 'MSCIUK', 'FTSEAllShare', 'FTSE250', 'FTSESmallCap', 'FTSEAIM']\n",
        "days_list = [1, 3, 5, 10, 20]\n",
        "\n",
        "for days in days_list:\n",
        "    result_row = [days]  # Start the row with the number of days\n",
        "    for index in indices:\n",
        "        df = globals()[f'df_{days}_day']  # Dynamically access each DataFrame\n",
        "\n",
        "        # Ensure 'Date' column is in datetime format\n",
        "        df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "        # Extract the month from the 'Date' column\n",
        "        df['Month'] = df['Date'].dt.month\n",
        "\n",
        "        # Create dummy variables for the months\n",
        "        month_dummies = pd.get_dummies(df['Month'], prefix='Month', drop_first=True)\n",
        "\n",
        "        # Convert boolean dummy variables to integers\n",
        "        month_dummies = month_dummies.astype(int)\n",
        "\n",
        "        # Define the dependent variable\n",
        "        y = df[f'% {index} Change']\n",
        "\n",
        "        # Define the independent variables\n",
        "        X = df[['Change in SWAV',\n",
        "                'ADS_Change',\n",
        "                'EPU_Change',\n",
        "                f'Previous % {index} Change',\n",
        "                '% MSCI Change',\n",
        "                'Vix Close',\n",
        "                'Rolling_Avg_Change_in_DCC']]\n",
        "\n",
        "        # Add the month dummies to the independent variables\n",
        "        X = pd.concat([X, month_dummies], axis=1)\n",
        "\n",
        "        # Convert all columns to numeric, coercing errors to NaN\n",
        "        X = X.apply(pd.to_numeric, errors='coerce')\n",
        "        y = pd.to_numeric(y, errors='coerce')\n",
        "\n",
        "        # Drop rows with any NaN values\n",
        "        X = X.dropna()\n",
        "        y = y.loc[X.index]  # Ensure 'y' aligns with 'X' after dropping NaNs\n",
        "\n",
        "        # Ensure that both X and y are aligned and are purely numeric\n",
        "        if X.shape[0] > 0 and y.shape[0] > 0:  # Proceed only if there's valid data\n",
        "            # Add a constant term to the model\n",
        "            X = sm.add_constant(X)\n",
        "\n",
        "            # Fit the model\n",
        "            model = sm.OLS(y, X).fit()\n",
        "\n",
        "            # Extract the coefficient and p-value for 'Change in SWAV'\n",
        "            coef = round(model.params['Change in SWAV'], 2)\n",
        "            p_value = round(model.pvalues['Change in SWAV'], 5)\n",
        "\n",
        "            # Store the coefficient and p-value as a tuple\n",
        "            result_row.append((coef, p_value))\n",
        "        else:\n",
        "            result_row.append((None, None))  # Store None for both if no valid data\n",
        "\n",
        "    # Append the result row for this combination of days\n",
        "    results.append(result_row)\n",
        "\n",
        "# Define column names dynamically, ensuring \"Days\" is the first column\n",
        "columns = ['Days']\n",
        "for index in indices:\n",
        "    columns.extend([f'{index} Coef'])  # Ensure you have columns for coefficients only\n",
        "\n",
        "# Convert the results list to a DataFrame, extracting only the coefficients\n",
        "results_df = pd.DataFrame([[row[0]] + [r[0] if isinstance(r, tuple) else None for r in row[1:]] for row in results], columns=columns)\n",
        "\n",
        "# Define a function to apply the styling based on significance\n",
        "def color_rows(row, original_results):\n",
        "    colors = []\n",
        "    for i in range(1, len(row)):  # Skip Days, then iterate through Coefs\n",
        "        # Safely access the original tuple\n",
        "        item = original_results[row.name][i]\n",
        "        if isinstance(item, tuple):\n",
        "            coef, p_value = item\n",
        "            if coef is not None and p_value < 0.1:  # Only color if p-value < 0.1 (significant)\n",
        "                if coef > 0:\n",
        "                    colors.append('background-color: green')\n",
        "                elif coef < 0:\n",
        "                    colors.append('background-color: red')\n",
        "                else:\n",
        "                    colors.append('')\n",
        "            else:\n",
        "                colors.append('')  # No color for non-significant or None\n",
        "        else:\n",
        "            colors.append('')  # No color if item is not a tuple\n",
        "    return [''] * 1 + colors  # No coloring for Days\n",
        "\n",
        "# Apply the function to each row of the DataFrame, passing the original results\n",
        "styled_df = results_df.style.apply(color_rows, axis=1, original_results=results)\n",
        "\n",
        "# Display the styled DataFrame\n",
        "styled_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TOP 5 HOLDINGS**"
      ],
      "metadata": {
        "id": "bMUxy3l44QuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "## Top 5 Holdings\n",
        "\n",
        "# Initialize an empty list to store results\n",
        "results = []\n",
        "\n",
        "indices = ['Barc', 'Voda', 'Glen', 'LLoyds', 'BP']\n",
        "days_list = [1, 3, 5, 10, 20]\n",
        "\n",
        "for days in days_list:\n",
        "    result_row = [days]  # Start the row with the number of days\n",
        "    for index in indices:\n",
        "        df = globals()[f'df_{days}_day']  # Dynamically access each DataFrame\n",
        "\n",
        "        # Ensure 'Date' column is in datetime format\n",
        "        df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "        # Extract the month from the 'Date' column\n",
        "        df['Month'] = df['Date'].dt.month\n",
        "\n",
        "        # Create dummy variables for the months\n",
        "        month_dummies = pd.get_dummies(df['Month'], prefix='Month', drop_first=True)\n",
        "\n",
        "        # Convert boolean dummy variables to integers\n",
        "        month_dummies = month_dummies.astype(int)\n",
        "\n",
        "        # Define the dependent variable\n",
        "        y = df[f'% {index} Change']\n",
        "\n",
        "        # Define the independent variables\n",
        "        X = df[['Change in SWAV',\n",
        "                'ADS_Change',\n",
        "                'EPU_Change',\n",
        "                f'Previous % {index} Change',\n",
        "                '% MSCI Change',\n",
        "                'Vix Close',\n",
        "                'Rolling_Avg_Change_in_DCC']]\n",
        "\n",
        "        # Add the month dummies to the independent variables\n",
        "        X = pd.concat([X, month_dummies], axis=1)\n",
        "\n",
        "        # Convert all columns to numeric, coercing errors to NaN\n",
        "        X = X.apply(pd.to_numeric, errors='coerce')\n",
        "        y = pd.to_numeric(y, errors='coerce')\n",
        "\n",
        "        # Drop rows with any NaN values\n",
        "        X = X.dropna()\n",
        "        y = y.loc[X.index]  # Ensure 'y' aligns with 'X' after dropping NaNs\n",
        "\n",
        "        # Ensure that both X and y are aligned and are purely numeric\n",
        "        if X.shape[0] > 0 and y.shape[0] > 0:  # Proceed only if there's valid data\n",
        "            # Add a constant term to the model\n",
        "            X = sm.add_constant(X)\n",
        "\n",
        "            # Fit the model\n",
        "            model = sm.OLS(y, X).fit()\n",
        "\n",
        "            # Extract the coefficient and p-value for 'Change in SWAV'\n",
        "            coef = round(model.params['Change in SWAV'], 2)\n",
        "            p_value = round(model.pvalues['Change in SWAV'], 5)\n",
        "\n",
        "            # Store the coefficient and p-value as a tuple\n",
        "            result_row.append((coef, p_value))\n",
        "        else:\n",
        "            result_row.append((None, None))  # Store None for both if no valid data\n",
        "\n",
        "    # Append the result row for this combination of days\n",
        "    results.append(result_row)\n",
        "\n",
        "# Define column names dynamically, ensuring \"Days\" is the first column\n",
        "columns = ['Days']\n",
        "for index in indices:\n",
        "    columns.extend([f'{index} Coef'])  # Ensure you have columns for coefficients only\n",
        "\n",
        "# Convert the results list to a DataFrame, extracting only the coefficients\n",
        "results_df = pd.DataFrame([[row[0]] + [r[0] if isinstance(r, tuple) else None for r in row[1:]] for row in results], columns=columns)\n",
        "\n",
        "# Define a function to apply the styling based on significance\n",
        "def color_rows(row, original_results):\n",
        "    colors = []\n",
        "    for i in range(1, len(row)):  # Skip Days, then iterate through Coefs\n",
        "        # Safely access the original tuple\n",
        "        item = original_results[row.name][i]\n",
        "        if isinstance(item, tuple):\n",
        "            coef, p_value = item\n",
        "            if coef is not None and p_value < 0.1:  # Only color if p-value < 0.1 (significant)\n",
        "                if coef > 0:\n",
        "                    colors.append('background-color: green')\n",
        "                elif coef < 0:\n",
        "                    colors.append('background-color: red')\n",
        "                else:\n",
        "                    colors.append('')\n",
        "            else:\n",
        "                colors.append('')  # No color for non-significant or None\n",
        "        else:\n",
        "            colors.append('')  # No color if item is not a tuple\n",
        "    return [''] * 1 + colors  # No coloring for Days\n",
        "\n",
        "# Apply the function to each row of the DataFrame, passing the original results\n",
        "styled_df = results_df.style.apply(color_rows, axis=1, original_results=results)\n",
        "\n",
        "# Display the styled DataFrame\n",
        "styled_df"
      ],
      "metadata": {
        "id": "Fs6XWPXQNYLI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "6c4209f1-ac7c-47be-dd38-1f92c3e92b00"
      },
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f63b51b6740>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_7afc9_row0_col4, #T_7afc9_row3_col4, #T_7afc9_row4_col1, #T_7afc9_row4_col2, #T_7afc9_row4_col4 {\n",
              "  background-color: green;\n",
              "}\n",
              "#T_7afc9_row1_col2, #T_7afc9_row2_col2, #T_7afc9_row3_col3, #T_7afc9_row3_col5, #T_7afc9_row4_col3, #T_7afc9_row4_col5 {\n",
              "  background-color: red;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_7afc9\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_7afc9_level0_col0\" class=\"col_heading level0 col0\" >Days</th>\n",
              "      <th id=\"T_7afc9_level0_col1\" class=\"col_heading level0 col1\" >Barc Coef</th>\n",
              "      <th id=\"T_7afc9_level0_col2\" class=\"col_heading level0 col2\" >Voda Coef</th>\n",
              "      <th id=\"T_7afc9_level0_col3\" class=\"col_heading level0 col3\" >Glen Coef</th>\n",
              "      <th id=\"T_7afc9_level0_col4\" class=\"col_heading level0 col4\" >LLoyds Coef</th>\n",
              "      <th id=\"T_7afc9_level0_col5\" class=\"col_heading level0 col5\" >BP Coef</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_7afc9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_7afc9_row0_col0\" class=\"data row0 col0\" >1</td>\n",
              "      <td id=\"T_7afc9_row0_col1\" class=\"data row0 col1\" >1.100000</td>\n",
              "      <td id=\"T_7afc9_row0_col2\" class=\"data row0 col2\" >-1.540000</td>\n",
              "      <td id=\"T_7afc9_row0_col3\" class=\"data row0 col3\" >-3.620000</td>\n",
              "      <td id=\"T_7afc9_row0_col4\" class=\"data row0 col4\" >9.130000</td>\n",
              "      <td id=\"T_7afc9_row0_col5\" class=\"data row0 col5\" >0.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_7afc9_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_7afc9_row1_col0\" class=\"data row1 col0\" >3</td>\n",
              "      <td id=\"T_7afc9_row1_col1\" class=\"data row1 col1\" >-1.690000</td>\n",
              "      <td id=\"T_7afc9_row1_col2\" class=\"data row1 col2\" >-7.210000</td>\n",
              "      <td id=\"T_7afc9_row1_col3\" class=\"data row1 col3\" >-5.240000</td>\n",
              "      <td id=\"T_7afc9_row1_col4\" class=\"data row1 col4\" >3.130000</td>\n",
              "      <td id=\"T_7afc9_row1_col5\" class=\"data row1 col5\" >-6.220000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_7afc9_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_7afc9_row2_col0\" class=\"data row2 col0\" >5</td>\n",
              "      <td id=\"T_7afc9_row2_col1\" class=\"data row2 col1\" >-0.880000</td>\n",
              "      <td id=\"T_7afc9_row2_col2\" class=\"data row2 col2\" >-8.450000</td>\n",
              "      <td id=\"T_7afc9_row2_col3\" class=\"data row2 col3\" >-4.630000</td>\n",
              "      <td id=\"T_7afc9_row2_col4\" class=\"data row2 col4\" >4.250000</td>\n",
              "      <td id=\"T_7afc9_row2_col5\" class=\"data row2 col5\" >-8.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_7afc9_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_7afc9_row3_col0\" class=\"data row3 col0\" >10</td>\n",
              "      <td id=\"T_7afc9_row3_col1\" class=\"data row3 col1\" >-4.050000</td>\n",
              "      <td id=\"T_7afc9_row3_col2\" class=\"data row3 col2\" >-7.940000</td>\n",
              "      <td id=\"T_7afc9_row3_col3\" class=\"data row3 col3\" >-14.660000</td>\n",
              "      <td id=\"T_7afc9_row3_col4\" class=\"data row3 col4\" >11.290000</td>\n",
              "      <td id=\"T_7afc9_row3_col5\" class=\"data row3 col5\" >-12.210000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_7afc9_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_7afc9_row4_col0\" class=\"data row4 col0\" >20</td>\n",
              "      <td id=\"T_7afc9_row4_col1\" class=\"data row4 col1\" >19.410000</td>\n",
              "      <td id=\"T_7afc9_row4_col2\" class=\"data row4 col2\" >14.400000</td>\n",
              "      <td id=\"T_7afc9_row4_col3\" class=\"data row4 col3\" >-23.110000</td>\n",
              "      <td id=\"T_7afc9_row4_col4\" class=\"data row4 col4\" >27.310000</td>\n",
              "      <td id=\"T_7afc9_row4_col5\" class=\"data row4 col5\" >-14.670000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 305
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **No Extreme FTSE Change Values**"
      ],
      "metadata": {
        "id": "Pwt6RVBDoO5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to store results\n",
        "results = []\n",
        "\n",
        "indices = ['FTSE100', 'MSCIUK', 'FTSEAllShare', 'FTSE250', 'FTSESmallCap', 'FTSEAIM']\n",
        "days_list = [1, 3, 5, 10, 20]\n",
        "\n",
        "for days in days_list:\n",
        "    result_row = [days]  # Start the row with the number of days\n",
        "    for index in indices:\n",
        "        df = globals()[f'df_{days}_day']  # Dynamically access each DataFrame\n",
        "\n",
        "        # Ensure 'Date' column is in datetime format\n",
        "        df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "        # Extract the month from the 'Date' column\n",
        "        df['Month'] = df['Date'].dt.month\n",
        "\n",
        "        # Create dummy variables for the months\n",
        "        month_dummies = pd.get_dummies(df['Month'], prefix='Month', drop_first=True)\n",
        "\n",
        "        # Convert boolean dummy variables to integers\n",
        "        month_dummies = month_dummies.astype(int)\n",
        "\n",
        "        # Define the dependent variable\n",
        "        y = df[f'% {index} Change']\n",
        "\n",
        "        # Calculate Z-scores for the percentage change in the index and create a new column safely\n",
        "        y_z = np.abs(stats.zscore(y))\n",
        "\n",
        "        # Filter for rows where the absolute Z-score is below the threshold (e.g., |Z| < 3)\n",
        "        no_extremes_mask = y_z < 3\n",
        "        y = y.loc[no_extremes_mask]\n",
        "        X = df.loc[no_extremes_mask, ['Change in SWAV',\n",
        "                                      'ADS_Change',\n",
        "                                      'EPU_Change',\n",
        "                                      f'Previous % {index} Change',\n",
        "                                      '% MSCI Change',\n",
        "                                      'Vix Close',\n",
        "                                      'Rolling_Avg_Change_in_DCC']]\n",
        "\n",
        "\n",
        "        # Add the month dummies to the independent variables\n",
        "        X = pd.concat([X, month_dummies.loc[no_extremes_mask]], axis=1)\n",
        "\n",
        "        # Convert all columns to numeric, coercing errors to NaN\n",
        "        X = X.apply(pd.to_numeric, errors='coerce')\n",
        "        y = pd.to_numeric(y, errors='coerce')\n",
        "\n",
        "        # Drop rows with any NaN values\n",
        "        X = X.dropna()\n",
        "        y = y.loc[X.index]  # Ensure 'y' aligns with 'X' after dropping NaNs\n",
        "\n",
        "        # Ensure that both X and y are aligned and are purely numeric\n",
        "        if X.shape[0] > 0 and y.shape[0] > 0:  # Proceed only if there's valid data\n",
        "            # Add a constant term to the model\n",
        "            X = sm.add_constant(X)\n",
        "\n",
        "            # Fit the model\n",
        "            model = sm.OLS(y, X).fit()\n",
        "\n",
        "            # Extract the coefficient and p-value for 'Change in SWAV'\n",
        "            coef = round(model.params['Change in SWAV'], 2)\n",
        "            p_value = round(model.pvalues['Change in SWAV'], 5)\n",
        "\n",
        "            # Store the coefficient and p-value as a tuple\n",
        "            result_row.append((coef, p_value))\n",
        "        else:\n",
        "            result_row.append((None, None))  # Store None for both if no valid data\n",
        "\n",
        "    # Append the result row for this combination of days\n",
        "    results.append(result_row)\n",
        "\n",
        "# Define column names dynamically, ensuring \"Days\" is the first column\n",
        "columns = ['Days']\n",
        "for index in indices:\n",
        "    columns.extend([f'{index} Coef'])  # Ensure you have columns for coefficients only\n",
        "\n",
        "# Convert the results list to a DataFrame, extracting only the coefficients\n",
        "results_df = pd.DataFrame([[row[0]] + [r[0] if isinstance(r, tuple) else None for r in row[1:]] for row in results], columns=columns)\n",
        "\n",
        "# Define a function to apply the styling based on significance\n",
        "def color_rows(row, original_results):\n",
        "    colors = []\n",
        "    for i in range(1, len(row)):  # Skip Days, then iterate through Coefs\n",
        "        # Safely access the original tuple\n",
        "        item = original_results[row.name][i]\n",
        "        if isinstance(item, tuple):\n",
        "            coef, p_value = item\n",
        "            if coef is not None and p_value < 0.1:  # Only color if p-value < 0.1 (significant)\n",
        "                if coef > 0:\n",
        "                    colors.append('background-color: green')\n",
        "                elif coef < 0:\n",
        "                    colors.append('background-color: red')\n",
        "                else:\n",
        "                    colors.append('')\n",
        "            else:\n",
        "                colors.append('')  # No color for non-significant or None\n",
        "        else:\n",
        "            colors.append('')  # No color if item is not a tuple\n",
        "    return [''] * 1 + colors  # No coloring for Days\n",
        "\n",
        "# Apply the function to each row of the DataFrame, passing the original results\n",
        "styled_df = results_df.style.apply(color_rows, axis=1, original_results=results)\n",
        "\n",
        "# Display the styled DataFrame\n",
        "styled_df"
      ],
      "metadata": {
        "id": "SWXkzuITfgC9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b3ed61ae-1ae6-4586-b3e1-d8c25344ec81"
      },
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f63b4923b80>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_49121_row1_col1, #T_49121_row1_col2, #T_49121_row1_col3, #T_49121_row2_col1, #T_49121_row2_col2, #T_49121_row2_col3, #T_49121_row2_col4, #T_49121_row2_col6, #T_49121_row3_col1, #T_49121_row3_col2, #T_49121_row3_col3, #T_49121_row3_col4, #T_49121_row3_col5, #T_49121_row3_col6, #T_49121_row4_col2, #T_49121_row4_col4, #T_49121_row4_col6 {\n",
              "  background-color: red;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_49121\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_49121_level0_col0\" class=\"col_heading level0 col0\" >Days</th>\n",
              "      <th id=\"T_49121_level0_col1\" class=\"col_heading level0 col1\" >FTSE100 Coef</th>\n",
              "      <th id=\"T_49121_level0_col2\" class=\"col_heading level0 col2\" >MSCIUK Coef</th>\n",
              "      <th id=\"T_49121_level0_col3\" class=\"col_heading level0 col3\" >FTSEAllShare Coef</th>\n",
              "      <th id=\"T_49121_level0_col4\" class=\"col_heading level0 col4\" >FTSE250 Coef</th>\n",
              "      <th id=\"T_49121_level0_col5\" class=\"col_heading level0 col5\" >FTSESmallCap Coef</th>\n",
              "      <th id=\"T_49121_level0_col6\" class=\"col_heading level0 col6\" >FTSEAIM Coef</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_49121_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_49121_row0_col0\" class=\"data row0 col0\" >1</td>\n",
              "      <td id=\"T_49121_row0_col1\" class=\"data row0 col1\" >-1.290000</td>\n",
              "      <td id=\"T_49121_row0_col2\" class=\"data row0 col2\" >0.210000</td>\n",
              "      <td id=\"T_49121_row0_col3\" class=\"data row0 col3\" >-1.080000</td>\n",
              "      <td id=\"T_49121_row0_col4\" class=\"data row0 col4\" >0.720000</td>\n",
              "      <td id=\"T_49121_row0_col5\" class=\"data row0 col5\" >1.400000</td>\n",
              "      <td id=\"T_49121_row0_col6\" class=\"data row0 col6\" >1.460000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_49121_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_49121_row1_col0\" class=\"data row1 col0\" >3</td>\n",
              "      <td id=\"T_49121_row1_col1\" class=\"data row1 col1\" >-4.020000</td>\n",
              "      <td id=\"T_49121_row1_col2\" class=\"data row1 col2\" >-2.720000</td>\n",
              "      <td id=\"T_49121_row1_col3\" class=\"data row1 col3\" >-3.870000</td>\n",
              "      <td id=\"T_49121_row1_col4\" class=\"data row1 col4\" >-0.980000</td>\n",
              "      <td id=\"T_49121_row1_col5\" class=\"data row1 col5\" >0.670000</td>\n",
              "      <td id=\"T_49121_row1_col6\" class=\"data row1 col6\" >-0.660000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_49121_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_49121_row2_col0\" class=\"data row2 col0\" >5</td>\n",
              "      <td id=\"T_49121_row2_col1\" class=\"data row2 col1\" >-6.530000</td>\n",
              "      <td id=\"T_49121_row2_col2\" class=\"data row2 col2\" >-3.850000</td>\n",
              "      <td id=\"T_49121_row2_col3\" class=\"data row2 col3\" >-5.910000</td>\n",
              "      <td id=\"T_49121_row2_col4\" class=\"data row2 col4\" >-3.660000</td>\n",
              "      <td id=\"T_49121_row2_col5\" class=\"data row2 col5\" >-0.440000</td>\n",
              "      <td id=\"T_49121_row2_col6\" class=\"data row2 col6\" >-3.680000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_49121_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_49121_row3_col0\" class=\"data row3 col0\" >10</td>\n",
              "      <td id=\"T_49121_row3_col1\" class=\"data row3 col1\" >-8.680000</td>\n",
              "      <td id=\"T_49121_row3_col2\" class=\"data row3 col2\" >-4.070000</td>\n",
              "      <td id=\"T_49121_row3_col3\" class=\"data row3 col3\" >-8.410000</td>\n",
              "      <td id=\"T_49121_row3_col4\" class=\"data row3 col4\" >-7.660000</td>\n",
              "      <td id=\"T_49121_row3_col5\" class=\"data row3 col5\" >-4.210000</td>\n",
              "      <td id=\"T_49121_row3_col6\" class=\"data row3 col6\" >-11.060000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_49121_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_49121_row4_col0\" class=\"data row4 col0\" >20</td>\n",
              "      <td id=\"T_49121_row4_col1\" class=\"data row4 col1\" >-3.060000</td>\n",
              "      <td id=\"T_49121_row4_col2\" class=\"data row4 col2\" >-6.010000</td>\n",
              "      <td id=\"T_49121_row4_col3\" class=\"data row4 col3\" >-3.530000</td>\n",
              "      <td id=\"T_49121_row4_col4\" class=\"data row4 col4\" >-6.240000</td>\n",
              "      <td id=\"T_49121_row4_col5\" class=\"data row4 col5\" >2.190000</td>\n",
              "      <td id=\"T_49121_row4_col6\" class=\"data row4 col6\" >-11.260000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 310
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Remove Extreme FTSE values and now remove bottom 10**"
      ],
      "metadata": {
        "id": "-NrVoyRjzxz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to store results\n",
        "results = []\n",
        "\n",
        "indices = ['FTSE100', 'MSCIUK', 'FTSEAllShare', 'FTSE250', 'FTSESmallCap', 'FTSEAIM']\n",
        "days_list = [1, 3, 5, 10, 20]\n",
        "\n",
        "for days in days_list:\n",
        "    result_row = [days]  # Start the row with the number of days\n",
        "    for index in indices:\n",
        "        df = globals()[f'df_{days}_day']  # Dynamically access each DataFrame\n",
        "\n",
        "        # Ensure 'Date' column is in datetime format\n",
        "        df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "        # Extract the month from the 'Date' column\n",
        "        df['Month'] = df['Date'].dt.month\n",
        "\n",
        "        # Create dummy variables for the months\n",
        "        month_dummies = pd.get_dummies(df['Month'], prefix='Month', drop_first=True)\n",
        "\n",
        "        # Convert boolean dummy variables to integers\n",
        "        month_dummies = month_dummies.astype(int)\n",
        "\n",
        "        # Define the dependent variable\n",
        "        y = df[f'% {index} Change']\n",
        "\n",
        "        # Define the independent variables\n",
        "        X = df[['Change in SWAV',\n",
        "                'ADS_Change',\n",
        "                'EPU_Change',\n",
        "                f'Previous % {index} Change',\n",
        "                '% MSCI Change',\n",
        "                'Vix Close',\n",
        "                'Rolling_Avg_Change_in_DCC']]\n",
        "\n",
        "        # Filter out the bottom 10% of Change in SWAV\n",
        "        lower_bound = X['Change in SWAV'].quantile(0.1)\n",
        "        X = X[X['Change in SWAV'] > lower_bound]\n",
        "        y = y.loc[X.index]  # Align y with the filtered X\n",
        "\n",
        "        # Remove outliers in index percentage changes using Z-scores\n",
        "        y_z_scores = np.abs(stats.zscore(y))\n",
        "        no_extremes_mask = y_z_scores < 3  # Filter out extreme Z-scores\n",
        "        X = X.loc[no_extremes_mask]\n",
        "        y = y.loc[no_extremes_mask]\n",
        "\n",
        "        # Apply the same mask to the month dummies to ensure alignment\n",
        "        month_dummies = month_dummies.loc[X.index]\n",
        "\n",
        "        # Add the month dummies to the independent variables\n",
        "        X = pd.concat([X, month_dummies], axis=1)\n",
        "\n",
        "        # Convert all columns to numeric, coercing errors to NaN\n",
        "        X = X.apply(pd.to_numeric, errors='coerce')\n",
        "        y = pd.to_numeric(y, errors='coerce')\n",
        "\n",
        "        # Drop rows with any NaN values\n",
        "        X = X.dropna()\n",
        "        y = y.loc[X.index]  # Ensure 'y' aligns with 'X' after dropping NaNs\n",
        "\n",
        "        # Ensure that both X and y are aligned and are purely numeric\n",
        "        if X.shape[0] > 0 and y.shape[0] > 0:  # Proceed only if there's valid data\n",
        "            # Add a constant term to the model\n",
        "            X = sm.add_constant(X)\n",
        "\n",
        "            # Fit the model\n",
        "            model = sm.OLS(y, X).fit()\n",
        "\n",
        "            # Extract the coefficient and p-value for 'Change in SWAV'\n",
        "            coef = round(model.params['Change in SWAV'], 2)\n",
        "            p_value = round(model.pvalues['Change in SWAV'], 5)\n",
        "\n",
        "            # Store the coefficient and p-value as a tuple\n",
        "            result_row.append((coef, p_value))\n",
        "        else:\n",
        "            result_row.append((None, None))  # Store None for both if no valid data\n",
        "\n",
        "    # Append the result row for this combination of days\n",
        "    results.append(result_row)\n",
        "\n",
        "# Define column names dynamically, ensuring \"Days\" is the first column\n",
        "columns = ['Days']\n",
        "for index in indices:\n",
        "    columns.extend([f'{index} Coef'])  # Ensure you have columns for coefficients only\n",
        "\n",
        "# Convert the results list to a DataFrame, extracting only the coefficients\n",
        "results_df = pd.DataFrame([[row[0]] + [r[0] if isinstance(r, tuple) else None for r in row[1:]] for row in results], columns=columns)\n",
        "\n",
        "# Define a function to apply the styling based on significance\n",
        "def color_rows(row, original_results):\n",
        "    colors = []\n",
        "    for i in range(1, len(row)):  # Skip Days, then iterate through Coefs\n",
        "        # Safely access the original tuple\n",
        "        item = original_results[row.name][i]\n",
        "        if isinstance(item, tuple):\n",
        "            coef, p_value = item\n",
        "            if coef is not None and p_value < 0.1:  # Only color if p-value < 0.1 (significant)\n",
        "                if coef > 0:\n",
        "                    colors.append('background-color: green')\n",
        "                elif coef < 0:\n",
        "                    colors.append('background-color: red')\n",
        "                else:\n",
        "                    colors.append('')\n",
        "            else:\n",
        "                colors.append('')  # No color for non-significant or None\n",
        "        else:\n",
        "            colors.append('')  # No color if item is not a tuple\n",
        "    return [''] * 1 + colors  # No coloring for Days\n",
        "\n",
        "# Apply the function to each row of the DataFrame, passing the original results\n",
        "styled_df = results_df.style.apply(color_rows, axis=1, original_results=results)\n",
        "\n",
        "# Display the styled DataFrame\n",
        "styled_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ADmZI2EOvND2",
        "outputId": "8e488f85-7cbf-4ec8-e9fc-b9ebb9103e29"
      },
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f63b8c5d840>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_5887f_row0_col5, #T_5887f_row0_col6, #T_5887f_row1_col5, #T_5887f_row1_col6, #T_5887f_row2_col5, #T_5887f_row2_col6, #T_5887f_row3_col5 {\n",
              "  background-color: green;\n",
              "}\n",
              "#T_5887f_row1_col1, #T_5887f_row1_col3, #T_5887f_row2_col1, #T_5887f_row4_col6 {\n",
              "  background-color: red;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_5887f\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_5887f_level0_col0\" class=\"col_heading level0 col0\" >Days</th>\n",
              "      <th id=\"T_5887f_level0_col1\" class=\"col_heading level0 col1\" >FTSE100 Coef</th>\n",
              "      <th id=\"T_5887f_level0_col2\" class=\"col_heading level0 col2\" >MSCIUK Coef</th>\n",
              "      <th id=\"T_5887f_level0_col3\" class=\"col_heading level0 col3\" >FTSEAllShare Coef</th>\n",
              "      <th id=\"T_5887f_level0_col4\" class=\"col_heading level0 col4\" >FTSE250 Coef</th>\n",
              "      <th id=\"T_5887f_level0_col5\" class=\"col_heading level0 col5\" >FTSESmallCap Coef</th>\n",
              "      <th id=\"T_5887f_level0_col6\" class=\"col_heading level0 col6\" >FTSEAIM Coef</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_5887f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_5887f_row0_col0\" class=\"data row0 col0\" >1</td>\n",
              "      <td id=\"T_5887f_row0_col1\" class=\"data row0 col1\" >-2.530000</td>\n",
              "      <td id=\"T_5887f_row0_col2\" class=\"data row0 col2\" >-1.140000</td>\n",
              "      <td id=\"T_5887f_row0_col3\" class=\"data row0 col3\" >-1.500000</td>\n",
              "      <td id=\"T_5887f_row0_col4\" class=\"data row0 col4\" >2.400000</td>\n",
              "      <td id=\"T_5887f_row0_col5\" class=\"data row0 col5\" >3.950000</td>\n",
              "      <td id=\"T_5887f_row0_col6\" class=\"data row0 col6\" >4.430000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5887f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_5887f_row1_col0\" class=\"data row1 col0\" >3</td>\n",
              "      <td id=\"T_5887f_row1_col1\" class=\"data row1 col1\" >-5.950000</td>\n",
              "      <td id=\"T_5887f_row1_col2\" class=\"data row1 col2\" >1.370000</td>\n",
              "      <td id=\"T_5887f_row1_col3\" class=\"data row1 col3\" >-4.200000</td>\n",
              "      <td id=\"T_5887f_row1_col4\" class=\"data row1 col4\" >0.570000</td>\n",
              "      <td id=\"T_5887f_row1_col5\" class=\"data row1 col5\" >4.180000</td>\n",
              "      <td id=\"T_5887f_row1_col6\" class=\"data row1 col6\" >5.420000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5887f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_5887f_row2_col0\" class=\"data row2 col0\" >5</td>\n",
              "      <td id=\"T_5887f_row2_col1\" class=\"data row2 col1\" >-5.030000</td>\n",
              "      <td id=\"T_5887f_row2_col2\" class=\"data row2 col2\" >2.820000</td>\n",
              "      <td id=\"T_5887f_row2_col3\" class=\"data row2 col3\" >-3.460000</td>\n",
              "      <td id=\"T_5887f_row2_col4\" class=\"data row2 col4\" >2.180000</td>\n",
              "      <td id=\"T_5887f_row2_col5\" class=\"data row2 col5\" >6.390000</td>\n",
              "      <td id=\"T_5887f_row2_col6\" class=\"data row2 col6\" >5.330000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5887f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_5887f_row3_col0\" class=\"data row3 col0\" >10</td>\n",
              "      <td id=\"T_5887f_row3_col1\" class=\"data row3 col1\" >-2.340000</td>\n",
              "      <td id=\"T_5887f_row3_col2\" class=\"data row3 col2\" >3.400000</td>\n",
              "      <td id=\"T_5887f_row3_col3\" class=\"data row3 col3\" >-2.160000</td>\n",
              "      <td id=\"T_5887f_row3_col4\" class=\"data row3 col4\" >-0.050000</td>\n",
              "      <td id=\"T_5887f_row3_col5\" class=\"data row3 col5\" >4.740000</td>\n",
              "      <td id=\"T_5887f_row3_col6\" class=\"data row3 col6\" >-1.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5887f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_5887f_row4_col0\" class=\"data row4 col0\" >20</td>\n",
              "      <td id=\"T_5887f_row4_col1\" class=\"data row4 col1\" >-0.510000</td>\n",
              "      <td id=\"T_5887f_row4_col2\" class=\"data row4 col2\" >3.070000</td>\n",
              "      <td id=\"T_5887f_row4_col3\" class=\"data row4 col3\" >-1.390000</td>\n",
              "      <td id=\"T_5887f_row4_col4\" class=\"data row4 col4\" >-4.600000</td>\n",
              "      <td id=\"T_5887f_row4_col5\" class=\"data row4 col5\" >0.690000</td>\n",
              "      <td id=\"T_5887f_row4_col6\" class=\"data row4 col6\" >-13.530000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 308
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPi6vhpPOU6vDeUOuO0r4lt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}